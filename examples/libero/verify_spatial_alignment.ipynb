{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94a4041",
   "metadata": {},
   "source": [
    "# 验证 Libero 环境中的空间对齐 (Spatial Alignment Verification)\n",
    "\n",
    "本 Notebook 旨在验证 Libero 环境中 3D 空间坐标（如机器人末端执行器位置）与 2D 相机图像之间的对齐准确性。\n",
    "\n",
    "我们将通过以下步骤进行验证：\n",
    "1.  初始化 Libero 仿真环境。\n",
    "2.  获取当前帧的相机图像和机器人的 3D 状态（末端执行器位置）。\n",
    "3.  利用相机内参和外参矩阵，将 3D 点投影到 2D 图像平面。\n",
    "4.  在图像上可视化投影点。如果投影点准确地落在图像中机器人的末端位置，则说明空间信息是准确的；反之则证明存在偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from libero.libero import benchmark\n",
    "from libero.libero.envs import OffScreenRenderEnv\n",
    "import robosuite.utils.camera_utils as camera_utils\n",
    "import robosuite.utils.transform_utils as T\n",
    "\n",
    "# 设置中文字体以支持绘图显示中文（如果在支持的环境中）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb741f62",
   "metadata": {},
   "source": [
    "## 1. 初始化 Libero 环境\n",
    "\n",
    "我们使用 `libero_spatial` 任务套件中的一个任务作为示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c81e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择任务套件和任务 ID\n",
    "TASK_SUITE_NAME = \"libero_spatial\"\n",
    "TASK_ID = 0\n",
    "IMAGE_WIDTH = 256\n",
    "IMAGE_HEIGHT = 256\n",
    "\n",
    "# 获取 Benchmark 和 Task\n",
    "benchmark_dict = benchmark.get_benchmark_dict()\n",
    "task_suite = benchmark_dict[TASK_SUITE_NAME]()\n",
    "task = task_suite.get_task(TASK_ID)\n",
    "init_states = task_suite.get_task_init_states(TASK_ID)\n",
    "\n",
    "print(f\"Task Name: {task.name}\")\n",
    "print(f\"Task Description: {task.language}\")\n",
    "\n",
    "# 创建环境\n",
    "env_args = {\n",
    "    \"bddl_file_name\": os.path.join(\n",
    "        os.path.dirname(benchmark.__file__), task.problem_folder, task.bddl_file\n",
    "    ),\n",
    "    \"render_gpu_device_id\": 0,\n",
    "    \"render_mode\": None,  # OffScreen rendering\n",
    "}\n",
    "\n",
    "env = OffScreenRenderEnv(**env_args)\n",
    "env.reset()\n",
    "env.set_init_state(init_states[0])\n",
    "\n",
    "# 执行一步以确保环境完全初始化\n",
    "obs, reward, done, info = env.step([0, 0, 0, 0, 0, 0, -1])  # Do nothing action\n",
    "print(\"环境初始化完成。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c62b24b",
   "metadata": {},
   "source": [
    "## 2. 获取 3D 坐标和相机参数并进行投影\n",
    "\n",
    "我们将获取机器人末端执行器 (End-Effector) 的世界坐标，并将其投影到 `agentview` 相机图像上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_point_to_image(sim, point_3d, camera_name, width, height):\n",
    "    \"\"\"\n",
    "    将 3D 点投影到相机图像平面。\n",
    "    \"\"\"\n",
    "    # 获取相机投影矩阵 (World -> Pixel)\n",
    "    # 注意：T_world_to_cam 可能是 4x4 矩阵\n",
    "    # robosuite 的 camera_utils.get_camera_transform_matrix 返回的是直接到像素坐标的变换矩阵\n",
    "    P = camera_utils.get_camera_transform_matrix(\n",
    "        sim=sim, \n",
    "        camera_name=camera_name, \n",
    "        camera_height=height, \n",
    "        camera_width=width\n",
    "    )\n",
    "    \n",
    "    # 构建齐次坐标\n",
    "    point_homogeneous = np.append(point_3d, 1.0)\n",
    "    \n",
    "    # 投影\n",
    "    point_pixel_homogeneous = P @ point_homogeneous\n",
    "    \n",
    "    # 归一化 (除以 w)\n",
    "    u = point_pixel_homogeneous[0] / point_pixel_homogeneous[2]\n",
    "    v = point_pixel_homogeneous[1] / point_pixel_homogeneous[2]\n",
    "    \n",
    "    return int(u), int(v)\n",
    "\n",
    "# 获取机器人末端执行器的位置\n",
    "# 在 Robosuite/Libero 中，通常是 'robot0_eef_pos' 或通过 sim 直接获取\n",
    "# 这里我们尝试直接从 sim 获取真实的 site 位置，这是最准确的 Ground Truth\n",
    "robot_eef_site_id = env.sim.model.site_name2id(\"robot0_eef\")\n",
    "eef_pos_3d = env.sim.data.site_xpos[robot_eef_site_id]\n",
    "\n",
    "print(f\"End-Effector 3D Position (World): {eef_pos_3d}\")\n",
    "\n",
    "# 获取图像\n",
    "camera_name = \"agentview\"\n",
    "# image key 通常是 camera_name + \"_image\"\n",
    "image_key = f\"{camera_name}_image\"\n",
    "\n",
    "if image_key in obs:\n",
    "    # 注意：Libero/Robosuite 图像通常是翻转的，需要检查 (H, W, C) 还是其他\n",
    "    # Robosuite env.step 返回的 obs 中的图像通常是上下颠倒的 (MuJoCo 默认渲染方式)\n",
    "    # 但 OffScreenRenderEnv 可能会处理这个。我们先直接读取。\n",
    "    image = obs[image_key]\n",
    "    \n",
    "    # 如果图像是浮点数 [0, 1]，转换为 uint8 [0, 255]\n",
    "    if image.dtype == np.float32 or image.dtype == np.float64:\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "    \n",
    "    # 投影\n",
    "    u, v = project_point_to_image(env.sim, eef_pos_3d, camera_name, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "    print(f\"Projected 2D Pixel: (u={u}, v={v})\")\n",
    "    \n",
    "    # 可视化\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # Robosuite 渲染出来的图经常是倒着的，我们先按原样显示，看看投影点在哪\n",
    "    # 如果投影点和图像里的机器人对应不上（比如图像倒了但点没变），说明图像需要翻转\n",
    "    plt.imshow(image)\n",
    "    plt.scatter([u], [v], c='r', s=100, marker='x', label='Projected EE Pos')\n",
    "    plt.title(f\"Camera: {camera_name} | EE projection verification\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # 也可以尝试翻转图像看是否对齐\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np.flipud(image))\n",
    "    plt.scatter([u], [IMAGE_HEIGHT - v], c='g', s=100, marker='x', label='Projected EE Pos (Flip Check)')\n",
    "    plt.title(f\"Camera: {camera_name} (Flipped) | EE projection verification\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(f\"Key {image_key} not found in observations. Available keys: {list(obs.keys())}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
